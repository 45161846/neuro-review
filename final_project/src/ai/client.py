import os
import json
from typing import Dict, Any, List
from openai import AsyncOpenAI
from ..config import settings


class AIClient:
    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.ai_api_key,
            base_url=settings.ai_base_url,
        )
        self.model = settings.ai_model
        self.max_tokens = settings.ai_max_tokens
        self.temperature = settings.ai_temperature
        self._prompt_template = self._load_prompt_template()

    def _load_prompt_template(self) -> str:
        dir_path = os.path.dirname(os.path.abspath(__file__))
        template_path = os.path.join(dir_path, "prompt_template.txt")
        with open(template_path, "r", encoding="utf-8") as file:
            return file.read()

    async def analyze_code_diff(
            self,
            diff_text: str,
            pr_title: str,
            repo_name: str,
            files_changed: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        prompt = self._build_review_prompt(diff_text, pr_title, repo_name, files_changed)
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert code reviewer."},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content
            return self._parse_ai_response(content)
        except Exception as e:
            return self._create_error_response(str(e))

    def _build_review_prompt(
            self,
            diff_text: str,
            pr_title: str,
            repo_name: str,
            files_changed: List[Dict[str, Any]]
    ) -> str:
        file_list = "\n".join([f"- {f.get('filename', 'unknown')}: {f.get('changes', 0)} changes"
                               for f in files_changed])
        return self._prompt_template.format(
            repository=repo_name,
            pr_title=pr_title,
            files_count=len(files_changed),
            file_list=file_list,
            diff_text=diff_text
        )

    def _parse_ai_response(self, response_text: str) -> Dict[str, Any]:
        try:
            data = json.loads(response_text)
            if not isinstance(data, dict):
                return self._create_error_response("Invalid response format")
            required_keys = ["success", "summary", "critical_issues", "suggestions"]
            if not all(key in data for key in required_keys):
                return self._create_error_response("Missing required fields in response")
            data["success"] = True
            return data
        except json.JSONDecodeError:
            return self._create_error_response("Failed to parse JSON response")

    def _create_error_response(self, error_msg: str) -> Dict[str, Any]:
        return {
            "success": False,
            "error": error_msg,
            "critical_issues": [],
            "suggestions": [],
            "summary": "Analysis failed"
        }

    def generate_comment_text(self, analysis: Dict[str, Any]) -> str:
        if not analysis.get("success", False):
            return "âŒ Failed to analyze code changes."
        critical_count = len(analysis.get("critical_issues", []))
        suggestions_count = len(analysis.get("suggestions", []))
        score = analysis.get("overall_quality_score", 0)
        comment = "## ðŸ¤– AI Code Review\n\n"
        comment += f"**Summary:** {analysis.get('summary', 'No summary provided')}\n\n"
        comment += f"**Quality Score:** {score}/100\n\n"
        if critical_count > 0:
            comment += f"### âš ï¸ Critical Issues ({critical_count})\n"
            for issue in analysis.get("critical_issues", [])[:5]:
                comment += f"- **{issue.get('file')}:{issue.get('line')}** - {issue.get('issue')}\n"
                if issue.get('suggestion'):
                    comment += f"  *Suggestion:* {issue.get('suggestion')}\n"
            comment += "\n"
        if suggestions_count > 0:
            comment += f"### ðŸ’¡ Suggestions ({suggestions_count})\n"
            for suggestion in analysis.get("suggestions", [])[:5]:
                comment += f"- **{suggestion.get('file')}:{suggestion.get('line')}** - {suggestion.get('suggestion')}\n"
            comment += "\n"
        if critical_count == 0 and suggestions_count == 0:
            comment += "âœ… No issues found. Code looks good!\n"
        comment += "*This review was generated by AI. Please verify critical issues manually.*"
        return comment